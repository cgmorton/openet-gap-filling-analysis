{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d90f48e-d126-405f-9db9-741a043dbbaf",
   "metadata": {},
   "source": [
    "## Input Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93d414a5-a80c-4e12-9c93-029ed0b5d66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The default is to include points from all NLCD classes and MGRS grid zones\n",
    "point_nlcd_keep_list = []\n",
    "point_mgrs_keep_list = []\n",
    "\n",
    "# # This would show all NLCD classes for MGRS grid zone 12T\n",
    "# point_nlcd_keep_list = [31, 41, 42, 43, 52, 71, 81, 82, 90, 95]\n",
    "# point_mgrs_keep_list = ['12T']\n",
    "\n",
    "# # This would show NLCD 82 points for all MGRS grid zones\n",
    "# point_nlcd_keep_list = [82]\n",
    "# point_mgrs_keep_list = []\n",
    "\n",
    "# The minimum number of months in the target year\n",
    "min_month_count = 3\n",
    "\n",
    "# Overwrite the summary stats file everytime this block is run\n",
    "output_txt = 'summary_stats_all_points.txt'\n",
    "output_f = open(output_txt, 'w')\n",
    "output_f.write('MGRS: '+ ', '.join(point_mgrs_keep_list) + '\\n')\n",
    "output_f.write('NLCD: '+ ', '.join(map(str, point_nlcd_keep_list)) + '\\n\\n')\n",
    "output_f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a40fb7-0897-4df9-9a1e-4c38d5d04859",
   "metadata": {},
   "source": [
    "## Other Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b344f6d7-85d4-43ce-b324-5507324660a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'data'\n",
    "points_folder = 'points'\n",
    "\n",
    "points_csv = 'gap_fill_test_points.csv'\n",
    "\n",
    "# Exclude 2016 from the statistics since there is not a full prior year to interpolate from\n",
    "# Including 2024 even though 2025 is not complete\n",
    "stats_years = list(range(2017, 2025))\n",
    "\n",
    "# Points were only built for NLCD 2024\n",
    "nlcd_years = [2024]\n",
    "\n",
    "# Include all MGRS grid zones except 12R and 16U since they are too small\n",
    "mgrs_zones = [\n",
    "    '10S', '10T', '10U', '11S', '11T', '11U', '12S', '12T', '12U', \n",
    "    '13R', '13S', '13T', '13U', '14R', '14S', '14T', '14U', '15R', '15S', '15T', '15U', \n",
    "    '16R', '16S', '16T', '17R', '17S', '17T', '18S', '18T', '19T'\n",
    "    # '12R', '16U'\n",
    "]\n",
    "\n",
    "months = list(range(1, 13))\n",
    "\n",
    "# TODO: Add support for setting a minimum number of months in the year\n",
    "#   and minimum number of months in the growing season\n",
    "# min_month_count = 6\n",
    "# min_gs_month_count = 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2b5fa0-cfb3-4282-a362-274c3663502c",
   "metadata": {},
   "source": [
    "## Python Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0566f07-3636-49a6-ac89-2e49c389a5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import math\n",
    "import os\n",
    "import pprint\n",
    "import random\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import seaborn as sns\n",
    "import sklearn.metrics\n",
    "import sklearn.linear_model\n",
    "\n",
    "from whittaker_eilers import WhittakerSmoother"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834b5275-f57c-476e-8048-82c4905230aa",
   "metadata": {},
   "source": [
    "## Read the point CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "110c7f91-bb58-46f5-9e08-43ea30237d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Points: 17084\n"
     ]
    }
   ],
   "source": [
    "# Building a single points dataframe and CSV from the MGRS grid zone points CSV files\n",
    "overwrite_flag = False\n",
    "\n",
    "# Read the separate points CSV files into a single dataframe\n",
    "points_df_list = [\n",
    "    pd.read_csv(os.path.join(points_folder, f'points_{mgrs_zone}_{nlcd_year}.csv'), index_col=None, header=0)\n",
    "    for nlcd_year in nlcd_years\n",
    "    for mgrs_zone in mgrs_zones\n",
    "    if os.path.isfile(os.path.join(points_folder, f'points_{mgrs_zone}_{nlcd_year}.csv'))\n",
    "]\n",
    "points_df = pd.concat(points_df_list, axis=0, ignore_index=True)\n",
    "print(f'Points: {len(points_df.index)}')\n",
    "\n",
    "# The mgrs_zone value will eventually be added to the csv files\n",
    "points_df['mgrs_zone'] = points_df['mgrs_tile'].str.slice(0, 3)\n",
    "\n",
    "# Add a unique index to the points dataframe\n",
    "points_df['index_group'] = points_df.groupby(['mgrs_tile', 'nlcd']).cumcount()\n",
    "points_df['point_id'] = (\n",
    "    points_df[\"mgrs_tile\"].str.upper() + '_' +\n",
    "    'nlcd' + points_df[\"nlcd\"].astype(str).str.zfill(2) + '_' +\n",
    "    points_df[\"index_group\"].astype(str).str.zfill(2)\n",
    ")\n",
    "del points_df['index_group']\n",
    "\n",
    "# Round the lat and lon to 8 decimal places (probably should be 6)\n",
    "points_df['latitude'] = round(points_df['latitude'], 8)\n",
    "points_df['longitude'] = round(points_df['longitude'], 8)\n",
    "\n",
    "# # Write to CSV\n",
    "# if not os.path.isfile(points_csv) or overwrite_flag:\n",
    "#     print('Writing points csv')\n",
    "#     points_df.to_csv(points_csv, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28a8885-d0db-4342-9394-b092d884976e",
   "metadata": {},
   "source": [
    "## Read the data CSV files\n",
    "\n",
    "This block may take a little while to execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0a385ac-dcce-4777-9649-73c2142d783e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading mgrs data csv files\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV files into separate dataframes for each point\n",
    "print('Reading mgrs data csv files')\n",
    "data_df_dict = {}\n",
    "for mgrs_zone in mgrs_zones:\n",
    "    # print(mgrs_zone)\n",
    "    if not os.path.isfile(os.path.join(data_folder, f'data_{mgrs_zone}.csv')):\n",
    "        continue\n",
    "        \n",
    "    mgrs_df = pd.read_csv(os.path.join(data_folder, f'data_{mgrs_zone}.csv'), index_col=None, header=0)\n",
    "\n",
    "    # Set MGRS value to upper case \n",
    "    # (at some point change this in all the data CSV files)\n",
    "    mgrs_df['mgrs_tile'] = mgrs_df['mgrs_tile'].str.upper()\n",
    "    mgrs_df['mgrs_zone'] = mgrs_df['mgrs_zone'].str.upper()\n",
    "    \n",
    "    # Compute the ET fraction\n",
    "    mgrs_df['etf'] = mgrs_df['et'] / mgrs_df['eto']\n",
    "    \n",
    "    # Get the month for computing climos\n",
    "    mgrs_df['date'] = pd.to_datetime(mgrs_df['date'])\n",
    "    mgrs_df['year'] = mgrs_df['date'].dt.year\n",
    "    mgrs_df['month'] = mgrs_df['date'].dt.month\n",
    "    \n",
    "    # Confirm that specific NLCD categories are not included\n",
    "    # TODO: This probably isn't needed and switch to a check instead of masking\n",
    "    for nlcd_skip in [11, 12, 21, 22, 23]:\n",
    "        mgrs_df = mgrs_df[mgrs_df['nlcd'] != nlcd_skip]\n",
    "\n",
    "    # Save dataframe for each point\n",
    "    for point_id in mgrs_df['point_id'].unique():\n",
    "        site_df = mgrs_df.loc[mgrs_df['point_id']==point_id].copy()\n",
    "        site_df.set_index('date', drop=True, inplace=True)\n",
    "        site_df.sort_index(inplace=True)\n",
    "        data_df_dict[point_id] = site_df\n",
    "        del site_df\n",
    "    del mgrs_df\n",
    "\n",
    "print('\\nDone')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07082839-61ea-40dc-b1f4-129298e6b006",
   "metadata": {},
   "source": [
    "## Compute the ETf climos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0859fc6d-d5aa-4eb3-8dfd-dfef1e9252be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing maximum ETf\n",
      "\n",
      "Computing monthly climatologies\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Compute the maximum ETf per site\n",
    "# Assuming it is okay to make this for the full period of record\n",
    "print('\\nComputing maximum ETf')\n",
    "etf_max_dict = {\n",
    "    point_id: data_df_dict[point_id].agg(etf=('etf', 'max'))['etf'].to_dict()['etf']\n",
    "    for point_id in data_df_dict.keys()\n",
    "}\n",
    "\n",
    "# Compute climos for each site\n",
    "# Only keep the climo value if there are at least \"n\" years of data\n",
    "print('\\nComputing monthly climatologies')\n",
    "month_climo_count_min = 2\n",
    "month_climo_dict = {}\n",
    "for point_id in data_df_dict.keys():\n",
    "    month_climo = data_df_dict[point_id].groupby(['month']).agg(\n",
    "        etf=('etf', 'mean'), \n",
    "        etf_median=('etf', 'median'), \n",
    "        count=('etf', 'count'), \n",
    "        et=('et', 'mean'), \n",
    "        eto=('eto', 'mean'),\n",
    "    )\n",
    "    month_climo_count_mask = month_climo['count'] < month_climo_count_min\n",
    "    month_climo.loc[month_climo_count_mask, ['etf', 'etf_median', 'et']] = np.nan\n",
    "    month_climo_dict[point_id] = month_climo\n",
    "    del month_climo, month_climo_count_mask\n",
    "\n",
    "# # Compute climos for each target year that have the target year values excluded\n",
    "# # CGM - This might be worth testing more but doesn't seem worth the time to generate\n",
    "# print('\\nComputing monthly climatologies for target years')\n",
    "# month_climo_dict = {}\n",
    "# for point_id in data_df_dict.keys():\n",
    "#     if point_id not in month_climo_dict.keys():\n",
    "#         month_climo_dict[point_id] = {}\n",
    "#     for year in stats_years:\n",
    "#         month_climo_dict[point_id][year] = (\n",
    "#             data_df_dict[point_id][data_df_dict[point_id].year != year]\n",
    "#             .groupby(['month'])\n",
    "#             .agg(\n",
    "#                 etf=('etf', 'mean'), \n",
    "#                 etf_median=('etf', 'median'), \n",
    "#                 count=('etf', 'count'), \n",
    "#                 et=('et', 'mean'), \n",
    "#                 eto=('eto', 'mean'),\n",
    "#             )\n",
    "#         )\n",
    "\n",
    "# TODO: Join the climo values to the data dictionaries\n",
    "#   It might be faster to join the climo data here instead of looking up in the function\n",
    "\n",
    "print('\\nDone')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bac573-9c39-43d6-a3ca-0ab5621321b7",
   "metadata": {},
   "source": [
    "## Functions for computing filled values and summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e098254-bb47-4817-94c7-97d21d1b3434",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_windows(\n",
    "        point_id_list, \n",
    "        months=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], \n",
    "        years=[2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024], \n",
    "        exclude_months_without_climo=True\n",
    "):\n",
    "    \"\"\"Generate Window Dataframes\"\"\"\n",
    "    for i, point_id in enumerate(point_id_list):\n",
    "        # Assume the data df dictionary exists in the global scope\n",
    "        site_df = data_df_dict[point_id]\n",
    "        \n",
    "        for year in years:\n",
    "            # Pull a three year window for each target year so that there are images to interpolate and fill from\n",
    "            window_df = site_df[(site_df.index.year >= (year-1)) & (site_df.index.year <= (year+1))].copy()\n",
    "\n",
    "            # If excluding months without climos, set them to NaN here\n",
    "            # TODO: Test out adding the climo values to the window_df here \n",
    "            #   instead of in the compute_filled_values() function below\n",
    "            if exclude_months_without_climo:\n",
    "                merge_df = pd.merge(window_df[['month']], month_climo_dict[point_id]['etf'], how=\"left\", on=\"month\")\n",
    "                climo_nan_mask = merge_df['etf'].isna().values\n",
    "                window_df.loc[climo_nan_mask, ['etf', 'et', 'count']] = np.nan\n",
    "\n",
    "            year_mask = window_df.index.year==year\n",
    "            year_month_mask = year_mask & window_df.index.month.isin(months)\n",
    "            \n",
    "            if window_df.loc[year_mask, 'etf'].count() < min_month_count:\n",
    "                # Check if there are enough months in the target year\n",
    "                # print(f'{point_id} - {i} - {year} - not enough unmasked months, skipping')\n",
    "                continue\n",
    "            elif window_df.loc[year_month_mask, 'etf'].isna().all():\n",
    "                # Check that there are target months with data in the \n",
    "                # print(f'{point_id} - {i} - {year} - no unmasked months in year/months, skipping')\n",
    "                continue\n",
    "            elif (window_df.loc[(window_df.index.year==year-1), 'etf'].isna().all() or \n",
    "                  window_df.loc[(window_df.index.year==year+1), 'etf'].isna().all()):\n",
    "                # Check if there is data in the prev/next year to interpolate from\n",
    "                # print(f'{point_id} - {i} - {year} - no unmasked months in next/prev year, skipping')\n",
    "                continue\n",
    "\n",
    "            yield point_id, year, window_df, year_month_mask\n",
    "\n",
    "\n",
    "comparison_cols = [\n",
    "    'interpolate', 'climo_mean', 'climo_median',\n",
    "    'conor',\n",
    "    'interp_clim_a', 'interp_clim_b', 'interp_clim_c',\n",
    "    'whit_a_0p50', 'whit_a_0p20', 'whit_a_0p10', 'whit_a_0p05', 'whit_a_0p01', \n",
    "]\n",
    "\n",
    "\n",
    "def compute_filled_values(window_df, tgt_indices, point_id):\n",
    "    \"\"\"\"\"\"\n",
    "    # Get a copy of the target value before clearing\n",
    "    original_etf = window_df.loc[tgt_indices, 'etf'].values\n",
    "        \n",
    "    # Set the target row values to NaN\n",
    "    window_df.loc[tgt_indices, ('etf', 'et', 'count')] = np.nan\n",
    "    \n",
    "    # Setup the Whittaker Smoothing for the full dataframe outside of the index loop\n",
    "    # The smoothing function needs all nans filled with a value\n",
    "    # The fill value is not important as long as the weight value is set to 0\n",
    "    window_df['temp'] = window_df['etf'].copy()\n",
    "    window_df.loc[np.isnan(window_df['temp']), 'temp'] = -1\n",
    "    etf = window_df['temp'].values\n",
    "\n",
    "    # TODO: Make sure weights are set to 0 for all temp==-1 rows\n",
    "    #   This might be happening already with the .fillna(0) call but double check\n",
    "    #   Right now the code is assuming count is NaN if etf is NaN\n",
    "    \n",
    "    # Default weights with 1 for data and 0 for missing values\n",
    "    weight_a = window_df['count'].clip(lower=1, upper=1).fillna(0)\n",
    "    if not any(weight_a):\n",
    "        print(f'{point_id} - {i} - {year} - all weights 0, skipping')\n",
    "        return []\n",
    "    # CGM - I tested out building the smoother once and then updating lambda,\n",
    "    #   but it didn't seem any faster\n",
    "    whit_a_0p50 = WhittakerSmoother(lmbda=0.5, order=2, data_length=len(weight_a), weights=weight_a).smooth(etf)\n",
    "    whit_a_0p20 = WhittakerSmoother(lmbda=0.2, order=2, data_length=len(weight_a), weights=weight_a).smooth(etf)\n",
    "    whit_a_0p10 = WhittakerSmoother(lmbda=0.1, order=2, data_length=len(weight_a), weights=weight_a).smooth(etf)\n",
    "    whit_a_0p05 = WhittakerSmoother(lmbda=0.05, order=2, data_length=len(weight_a), weights=weight_a).smooth(etf)\n",
    "    whit_a_0p01 = WhittakerSmoother(lmbda=0.01, order=2, data_length=len(weight_a), weights=weight_a).smooth(etf)\n",
    "\n",
    "    # CGM - I was testing out trying different weights but it didn't seem to change the values at all\n",
    "    # # Compute weights based on the the scene count value\n",
    "    # # Set count 0 images to a weight of 0\n",
    "    # weight = window_df['count'].clip(lower=0, upper=1).fillna(0)\n",
    "\n",
    "    # # Compute weights based on the the scene count value\n",
    "    # # Set counts of 0 to a weight of 0.5 and all other to 1    \n",
    "    # weight = window_df['count'].add(1).clip(upper=2).divide(2).fillna(0)\n",
    "\n",
    "    # # Compute weights based on the scene count value\n",
    "    # # Set count weights as: 0 -> 0, 1 -> 0.5, 2+ -> 1\n",
    "    # weight = window_df['count'].fillna(0).clip(upper=2).divide(2)\n",
    "    \n",
    "    # Process each target index separately\n",
    "    values = []\n",
    "    for i, (tgt_index, tgt_i) in enumerate(zip(tgt_indices, window_df.index.get_indexer(tgt_indices))):\n",
    "\n",
    "        interp_value = window_df['etf'].interpolate(method='linear').loc[tgt_index]\n",
    "\n",
    "        # Climos for all years\n",
    "        climo_mean = month_climo_dict[point_id].loc[tgt_index.month, 'etf']\n",
    "        climo_count = month_climo_dict[point_id].loc[tgt_index.month, 'count']\n",
    "        climo_median = month_climo_dict[point_id].loc[tgt_index.month, 'etf_median']\n",
    "        # # Climos with the target year excluded (not sure if this matters)\n",
    "        # climo_mean = month_climo_dict[point_id][tgt_index.year].loc[tgt_index.month, 'etf']\n",
    "        # climo_count = month_climo_dict[point_id][tgt_index.year].loc[tgt_index.month, 'count']\n",
    "        # climo_median = month_climo_dict[point_id][tgt_index.year].loc[tgt_index.month, 'etf_median']\n",
    "\n",
    "        # Compute various combinations of averaging the climo and interpolate values\n",
    "        # Simple mean\n",
    "        interp_clim_a = (climo_mean + interp_value) / 2\n",
    "        # Simple mean with the median climo\n",
    "        interp_clim_c = (climo_median + interp_value) / 2\n",
    "        # Weight the climo based on the number of months in the climo?\n",
    "        climo_months = 10\n",
    "        interp_clim_b = (climo_mean * climo_count + interp_value * climo_months) / (climo_count + climo_months)\n",
    "\n",
    "        # Conor's Approach\n",
    "        # There is probably an easier way, but splitting the dataframe at the target index seemed to work pretty well\n",
    "        window_prev_df = window_df.iloc[:tgt_i]\n",
    "        window_next_df = window_df.iloc[tgt_i+1:]\n",
    "        prev_index = window_prev_df['etf'].last_valid_index()\n",
    "        next_index = window_next_df['etf'].first_valid_index()\n",
    "        prev_i = window_df.index.get_loc(prev_index)\n",
    "        next_i = window_df.index.get_loc(next_index)\n",
    "        w_prev = 0.5 * math.exp(1 - (tgt_i - prev_i))\n",
    "        w_next = 0.5 * math.exp(1 - (next_i - tgt_i))\n",
    "        value_prev = window_df['etf'].iloc[prev_i]\n",
    "        value_next = window_df['etf'].iloc[next_i]\n",
    "        climo_prev = month_climo_dict[point_id].loc[prev_index.month, 'etf']\n",
    "        climo_next = month_climo_dict[point_id].loc[next_index.month, 'etf']\n",
    "        conor = w_prev * (value_prev - climo_prev) + w_next * (value_next - climo_next) + climo_mean\n",
    "\n",
    "        values.append({\n",
    "            'index': tgt_index,\n",
    "            'point_id': point_id,\n",
    "            'mgrs': point_id.split('_')[0],\n",
    "            'nlcd': int(point_id.split('_')[1][4:6]),\n",
    "            'original': original_etf[i],\n",
    "            # Filled values\n",
    "            'interpolate': interp_value,\n",
    "            'climo_mean': climo_mean,\n",
    "            'climo_median': climo_median,\n",
    "            'conor': conor,\n",
    "            'interp_clim_a': interp_clim_a,\n",
    "            'interp_clim_b': interp_clim_b,\n",
    "            'interp_clim_c': interp_clim_c,\n",
    "            'whit_a_0p50': min(max(whit_a_0p50[tgt_i], 0), etf_max_dict[point_id]),\n",
    "            'whit_a_0p20': min(max(whit_a_0p20[tgt_i], 0), etf_max_dict[point_id]),\n",
    "            'whit_a_0p10': min(max(whit_a_0p10[tgt_i], 0), etf_max_dict[point_id]),\n",
    "            'whit_a_0p05': min(max(whit_a_0p05[tgt_i], 0), etf_max_dict[point_id]),\n",
    "            'whit_a_0p01': min(max(whit_a_0p01[tgt_i], 0), etf_max_dict[point_id]),\n",
    "            \n",
    "        })\n",
    "\n",
    "    return values\n",
    "\n",
    "\n",
    "def comparison_stats(df, x_col='original', y_cols=[], title='', print_flag=True, write_flag=True):\n",
    "    \"\"\"\"\"\"\n",
    "    output = [title]\n",
    "\n",
    "    # TODO: Build the format strings based on the number of parameters instead of hardcoding\n",
    "    output.append('  {:>16s} {:>8s} {:>8s} {:>8s} {:>8s} {:>8s} {:>8s} {:>8s}'.format(\n",
    "        'method', 'rmse', 'mae', 'mbe', 'm', 'b', 'r2', 'n'\n",
    "    ))\n",
    "    for y_col in y_cols:\n",
    "        # Remove any NaN rows before computing statistics\n",
    "        stat_df = df[df[y_col].notna()]\n",
    "        model = sklearn.linear_model.LinearRegression()\n",
    "        model.fit(stat_df[[x_col]], stat_df[y_col])\n",
    "\n",
    "        output.append('  {:>16s} {:8.4f} {:8.4f} {:8.4f} {:8.4f} {:8.4f} {:8.4f} {:8d}'.format(\n",
    "            y_col,\n",
    "            sklearn.metrics.root_mean_squared_error(stat_df[x_col], stat_df[y_col]),\n",
    "            sklearn.metrics.mean_absolute_error(stat_df[x_col], stat_df[y_col]),\n",
    "            np.mean(stat_df[y_col] - stat_df[x_col]),\n",
    "            # np.mean(stat_df[x_col] - stat_df[y_col]),\n",
    "            # sklearn.metrics.r2_score(stat_df[x_col], stat_df[y_col]),\n",
    "            model.coef_[0],\n",
    "            model.intercept_, \n",
    "            model.score(stat_df[[x_col]], stat_df[y_col]),\n",
    "            # This count doesn't seem to change even when there are NaN values in the dataframe\n",
    "            stat_df[y_col].count(),\n",
    "        ))\n",
    "\n",
    "    if print_flag:\n",
    "        print('\\n'.join(output))\n",
    "    if write_flag:\n",
    "        with open(output_txt, 'a') as output_f:\n",
    "            output_f.write('\\n'.join(output+ ['\\n']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8377da-fd13-4608-a08d-be32d7a1a663",
   "metadata": {},
   "source": [
    "## Filter to the target MGRS and NLCD classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e132870-a3f3-4911-97bf-daff82dd483b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Points: 17083\n"
     ]
    }
   ],
   "source": [
    "# Filter the points list to the target NLCD classes and MGRS grid zones\n",
    "point_id_list = list(data_df_dict.keys())\n",
    "if point_nlcd_keep_list:\n",
    "    point_id_list = [p for p in point_id_list if int(p.split('_')[1][4:6]) in point_nlcd_keep_list]\n",
    "if point_mgrs_keep_list:\n",
    "    point_id_list = [p for p in point_id_list if p.split('_')[0][0:3] in point_mgrs_keep_list]\n",
    "\n",
    "print(f'Points: {len(point_id_list)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43c6d67-d25c-4ab1-bb66-1b1d8f7c0bc6",
   "metadata": {},
   "source": [
    "## Randomly drop one datapoint in each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50b39b93-ee41-4f1f-8e82-1d4b01506fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly drop one datapoint in each year\n",
      "            method     rmse      mae      mbe        m        b       r2        n\n",
      "       interpolate   0.1186   0.0883   0.0015   0.8639   0.0866   0.8609   136547\n",
      "        climo_mean   0.1225   0.0905   0.0011   0.8516   0.0938   0.8516   136547\n",
      "      climo_median   0.1265   0.0871   0.0004   0.8733   0.0796   0.8429   136547\n",
      "             conor   0.1007   0.0752  -0.0003   0.9200   0.0497   0.9002   136547\n",
      "     interp_clim_a   0.1058   0.0794   0.0013   0.8578   0.0902   0.8905   136547\n",
      "     interp_clim_b   0.1066   0.0798   0.0016   0.8574   0.0907   0.8889   136547\n",
      "     interp_clim_c   0.1067   0.0783   0.0010   0.8686   0.0831   0.8879   136547\n",
      "       whit_a_0p50   0.1203   0.0894   0.0010   0.8760   0.0785   0.8572   136547\n",
      "       whit_a_0p20   0.1191   0.0881   0.0007   0.8918   0.0683   0.8608   136547\n",
      "       whit_a_0p10   0.1195   0.0883   0.0005   0.8995   0.0634   0.8606   136547\n",
      "       whit_a_0p05   0.1204   0.0889   0.0004   0.9043   0.0602   0.8591   136547\n",
      "       whit_a_0p01   0.1222   0.0903   0.0002   0.9091   0.0570   0.8558   136547\n"
     ]
    }
   ],
   "source": [
    "months = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "\n",
    "output_list = []\n",
    "for point_id, year, window_df, year_month_mask in generate_windows(point_id_list, months=months):        \n",
    "    tgt_mask = year_month_mask & window_df['etf'].notna()\n",
    "    if not tgt_mask.any():\n",
    "        print(f'{point_id} - {year} - no unmasked months, skipping')\n",
    "        continue\n",
    "            \n",
    "    tgt_indices = window_df.loc[tgt_mask].sample(n=1).index\n",
    "    output_list.extend(compute_filled_values(window_df, tgt_indices, point_id))\n",
    "    \n",
    "output_df = pd.DataFrame(output_list)\n",
    "comparison_stats(\n",
    "    output_df, x_col='original', y_cols=comparison_cols, \n",
    "    title='Randomly drop one datapoint in each year',\n",
    "    print_flag=True, write_flag=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946f92d5-ed52-4014-9d17-cdf366b5f037",
   "metadata": {},
   "source": [
    "## Randomly drop a single datapoint from the \"growing\" season (Apr-Sept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "166f5235-e91b-405d-a7c5-adadfbcdb36a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly drop a single datapoint from the \"growing\" season (Apr-Sept)\n",
      "            method     rmse      mae      mbe        m        b       r2        n\n",
      "       interpolate   0.1032   0.0778  -0.0115   0.8915   0.0646   0.9074   136544\n",
      "        climo_mean   0.1160   0.0845   0.0022   0.8805   0.0861   0.8811   136544\n",
      "      climo_median   0.1201   0.0815   0.0047   0.9012   0.0740   0.8737   136544\n",
      "             conor   0.0871   0.0656   0.0004   0.9450   0.0390   0.9332   136544\n",
      "     interp_clim_a   0.0950   0.0717  -0.0047   0.8860   0.0753   0.9219   136544\n",
      "     interp_clim_b   0.0951   0.0717  -0.0047   0.8860   0.0753   0.9217   136544\n",
      "     interp_clim_c   0.0957   0.0705  -0.0034   0.8964   0.0693   0.9198   136544\n",
      "       whit_a_0p50   0.1054   0.0792  -0.0059   0.9034   0.0618   0.9021   136544\n",
      "       whit_a_0p20   0.1031   0.0772  -0.0031   0.9189   0.0538   0.9063   136544\n",
      "       whit_a_0p10   0.1028   0.0769  -0.0020   0.9262   0.0498   0.9071   136544\n",
      "       whit_a_0p05   0.1032   0.0772  -0.0013   0.9307   0.0473   0.9066   136544\n",
      "       whit_a_0p01   0.1044   0.0782  -0.0008   0.9351   0.0448   0.9048   136544\n"
     ]
    }
   ],
   "source": [
    "months = [4, 5, 6, 7, 8, 9]\n",
    "\n",
    "output_list = []\n",
    "for point_id, year, window_df, year_month_mask in generate_windows(point_id_list, months=months):        \n",
    "    tgt_mask = year_month_mask & window_df['etf'].notna()\n",
    "    if not tgt_mask.any():\n",
    "        print(f'{point_id} - {year} - no unmasked months, skipping')\n",
    "        continue\n",
    "        \n",
    "    tgt_indices = window_df.loc[tgt_mask].sample(n=1).index\n",
    "    output_list.extend(compute_filled_values(window_df, tgt_indices, point_id))\n",
    "    \n",
    "output_df = pd.DataFrame(output_list)\n",
    "comparison_stats(\n",
    "    output_df, x_col='original', y_cols=comparison_cols, \n",
    "    title='Randomly drop a single datapoint from the \"growing\" season (Apr-Sept)',\n",
    "    print_flag=True, write_flag=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb23c78-f2d8-4f3f-a319-24219a9b5256",
   "metadata": {},
   "source": [
    "## Randomly drop a single datapoint from the \"non-growing\" season (Oct-Mar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02ec9dbe-9418-436b-97be-3d6c4cc2480c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly drop a single datapoint from the \"non-growing\" season (Oct-Mar)\n",
      "            method     rmse      mae      mbe        m        b       r2        n\n",
      "       interpolate   0.1391   0.1041   0.0215   0.8171   0.1180   0.7395   135764\n",
      "        climo_mean   0.1320   0.0997  -0.0001   0.7486   0.1326   0.7524   135764\n",
      "      climo_median   0.1362   0.0959  -0.0047   0.7671   0.1181   0.7377   135764\n",
      "             conor   0.1168   0.0884  -0.0016   0.8409   0.0824   0.8073   135764\n",
      "     interp_clim_a   0.1201   0.0912   0.0107   0.7829   0.1253   0.7966   135764\n",
      "     interp_clim_b   0.1218   0.0922   0.0117   0.7831   0.1262   0.7909   135764\n",
      "     interp_clim_c   0.1211   0.0901   0.0084   0.7921   0.1181   0.7925   135764\n",
      "       whit_a_0p50   0.1399   0.1045   0.0124   0.8149   0.1101   0.7330   135764\n",
      "       whit_a_0p20   0.1399   0.1041   0.0075   0.8242   0.1003   0.7336   135764\n",
      "       whit_a_0p10   0.1411   0.1049   0.0054   0.8297   0.0952   0.7306   135764\n",
      "       whit_a_0p05   0.1427   0.1060   0.0041   0.8336   0.0919   0.7265   135764\n",
      "       whit_a_0p01   0.1453   0.1080   0.0028   0.8378   0.0885   0.7193   135764\n"
     ]
    }
   ],
   "source": [
    "months = [10, 11, 12, 1, 2, 3]\n",
    "\n",
    "output_list = []\n",
    "for point_id, year, window_df, year_month_mask in generate_windows(point_id_list, months=months):        \n",
    "    tgt_mask = year_month_mask & window_df['etf'].notna()\n",
    "    if not tgt_mask.any():\n",
    "        print(f'{point_id} - {year} - no unmasked months, skipping')\n",
    "        continue\n",
    "            \n",
    "    tgt_indices = window_df.loc[tgt_mask].sample(n=1).index\n",
    "    output_list.extend(compute_filled_values(window_df, tgt_indices, point_id))\n",
    "    \n",
    "output_df = pd.DataFrame(output_list)\n",
    "comparison_stats(\n",
    "    output_df, x_col='original', y_cols=comparison_cols, \n",
    "    title='Randomly drop a single datapoint from the \"non-growing\" season (Oct-Mar)',\n",
    "    print_flag=True, write_flag=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0e6a9c-15f7-49b4-924b-151d16fb06fc",
   "metadata": {},
   "source": [
    "## Randomly drop a datapoint from the winter (Dec-Feb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1babf7f8-8504-46f5-9094-e2bfa9957eb7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly drop a datapoint from the winter (Dec-Feb)\n",
      "            method     rmse      mae      mbe        m        b       r2        n\n",
      "       interpolate   0.1452   0.1076   0.0227   0.7674   0.1344   0.6771   115357\n",
      "        climo_mean   0.1374   0.1038   0.0027   0.6930   0.1502   0.6924   115357\n",
      "      climo_median   0.1419   0.0990  -0.0042   0.7095   0.1353   0.6740   115357\n",
      "             conor   0.1244   0.0934   0.0018   0.7988   0.0985   0.7511   115357\n",
      "     interp_clim_a   0.1268   0.0954   0.0127   0.7302   0.1423   0.7407   115357\n",
      "     interp_clim_b   0.1299   0.0971   0.0144   0.7299   0.1441   0.7284   115357\n",
      "     interp_clim_c   0.1279   0.0940   0.0093   0.7385   0.1349   0.7348   115357\n",
      "       whit_a_0p50   0.1453   0.1073   0.0092   0.7611   0.1240   0.6700   115357\n",
      "       whit_a_0p20   0.1460   0.1075   0.0049   0.7690   0.1158   0.6684   115357\n",
      "       whit_a_0p10   0.1475   0.1086   0.0035   0.7743   0.1119   0.6639   115357\n",
      "       whit_a_0p05   0.1494   0.1099   0.0029   0.7783   0.1093   0.6584   115357\n",
      "       whit_a_0p01   0.1523   0.1122   0.0025   0.7829   0.1068   0.6496   115357\n"
     ]
    }
   ],
   "source": [
    "months = [12, 1, 2]\n",
    "\n",
    "output_list = []\n",
    "for point_id, year, window_df, year_month_mask in generate_windows(point_id_list, months=months):        \n",
    "    tgt_mask = year_month_mask & window_df['etf'].notna()\n",
    "    if not tgt_mask.any():\n",
    "        print(f'{point_id} - {year} - no unmasked months, skipping')\n",
    "        continue\n",
    "            \n",
    "    tgt_indices = window_df.loc[tgt_mask].sample(n=1).index\n",
    "    output_list.extend(compute_filled_values(window_df, tgt_indices, point_id))\n",
    "\n",
    "output_df = pd.DataFrame(output_list)\n",
    "comparison_stats(\n",
    "    output_df, x_col='original', y_cols=comparison_cols, \n",
    "    title='Randomly drop a datapoint from the winter (Dec-Feb)',\n",
    "    print_flag=True, write_flag=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c67980-1688-4c45-a350-0f3c2e3cd6bc",
   "metadata": {},
   "source": [
    "## Randomly drop a single datapoint that is next to an existing missing data point "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f552ebe2-3c51-4355-bae3-cc4758f8ba73",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly drop a single datapoint that is next to an existing missing data point\n",
      "            method     rmse      mae      mbe        m        b       r2        n\n",
      "       interpolate   0.1815   0.1405   0.0325   0.7004   0.2079   0.6099    64295\n",
      "        climo_mean   0.1509   0.1150  -0.0069   0.7022   0.1675   0.7126    64295\n",
      "      climo_median   0.1572   0.1113  -0.0126   0.7163   0.1535   0.6904    64295\n",
      "             conor   0.1397   0.1065  -0.0063   0.7519   0.1389   0.7538    64295\n",
      "     interp_clim_a   0.1494   0.1155   0.0128   0.7013   0.1877   0.7200    64295\n",
      "     interp_clim_b   0.1531   0.1181   0.0151   0.6975   0.1922   0.7063    64295\n",
      "     interp_clim_c   0.1511   0.1147   0.0100   0.7084   0.1807   0.7125    64295\n",
      "       whit_a_0p50   0.1833   0.1412   0.0143   0.7221   0.1771   0.6017    64295\n",
      "       whit_a_0p20   0.1843   0.1415   0.0070   0.7381   0.1604   0.6016    64295\n",
      "       whit_a_0p10   0.1865   0.1430   0.0038   0.7465   0.1523   0.5972    64295\n",
      "       whit_a_0p05   0.1890   0.1449   0.0019   0.7521   0.1471   0.5916    64295\n",
      "       whit_a_0p01   0.1929   0.1479   0.0001   0.7577   0.1419   0.5822    64295\n"
     ]
    }
   ],
   "source": [
    "months = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "\n",
    "output_list = []\n",
    "for point_id, year, window_df, year_month_mask in generate_windows(point_id_list, months=months):        \n",
    "\n",
    "    # Skip the year if there are no NaN values\n",
    "    if not window_df.loc[year_month_mask, 'etf'].isna().any():\n",
    "        # print(f'{point_id} - {i} - {year} - no missing data points, skipping')\n",
    "        continue\n",
    "    \n",
    "    # For the target year, pick a random month that is next to a missing/masked month but has data\n",
    "    nan_mask = window_df['etf'].isna()\n",
    "    tgt_mask = (\n",
    "        (nan_mask | nan_mask.shift(1) | nan_mask.shift(-1))\n",
    "        & window_df['etf'].notna() & year_month_mask\n",
    "    )\n",
    "    if not tgt_mask.any():\n",
    "        print(f'{point_id} - {i} - {year} - no unmasked months, skipping')\n",
    "        continue\n",
    "            \n",
    "    tgt_indices = window_df.loc[tgt_mask].sample(n=1).index\n",
    "    output_list.extend(compute_filled_values(window_df, tgt_indices, point_id))\n",
    "    \n",
    "output_df = pd.DataFrame(output_list)\n",
    "comparison_stats(\n",
    "    output_df, x_col='original', y_cols=comparison_cols, \n",
    "    title='Randomly drop a single datapoint that is next to an existing missing data point',\n",
    "    print_flag=True, write_flag=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66253449-70e8-456f-a371-3991b53abcad",
   "metadata": {},
   "source": [
    "## Randomly drop a two month gap during the year\n",
    "\n",
    "But only check the filled value in one month of the gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cde2557-3a46-40ea-b234-33865b5247dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly drop a two month gap during the year\n",
      "            method     rmse      mae      mbe        m        b       r2        n\n",
      "       interpolate   0.1426   0.1070   0.0042   0.8155   0.1186   0.7978   136547\n",
      "        climo_mean   0.1240   0.0918   0.0014   0.8467   0.0966   0.8467   136547\n",
      "      climo_median   0.1283   0.0885   0.0005   0.8679   0.0824   0.8371   136547\n",
      "             conor   0.1071   0.0802   0.0002   0.8889   0.0692   0.8856   136547\n",
      "     interp_clim_a   0.1162   0.0879   0.0028   0.8311   0.1076   0.8668   136547\n",
      "     interp_clim_b   0.1178   0.0888   0.0035   0.8298   0.1090   0.8630   136547\n",
      "     interp_clim_c   0.1168   0.0868   0.0023   0.8417   0.1005   0.8646   136547\n",
      "       whit_a_0p50   0.1432   0.1068   0.0034   0.8459   0.0990   0.7986   136547\n",
      "       whit_a_0p20   0.1435   0.1065   0.0028   0.8633   0.0875   0.7999   136547\n",
      "       whit_a_0p10   0.1450   0.1075   0.0024   0.8716   0.0821   0.7974   136547\n",
      "       whit_a_0p05   0.1469   0.1089   0.0021   0.8767   0.0786   0.7936   136547\n",
      "       whit_a_0p01   0.1500   0.1113   0.0018   0.8815   0.0753   0.7869   136547\n"
     ]
    }
   ],
   "source": [
    "dropped_months = 2\n",
    "months = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "\n",
    "output_list = []\n",
    "for point_id, year, window_df, year_month_mask in generate_windows(point_id_list, months=months):        \n",
    "\n",
    "    # For the target year, identify all the gap windows with at least 1 month of data\n",
    "    # This approach is assuming the gap will be 2 or months in the gap\n",
    "    gap_mask = window_df['etf'].notna()\n",
    "    for i in range(dropped_months-1):\n",
    "        gap_mask = gap_mask | window_df['etf'].notna().shift(-(i+1))\n",
    "        \n",
    "    tgt_mask = year_month_mask & gap_mask\n",
    "    if not tgt_mask.any():\n",
    "        print(f'{point_id} - {year} - no unmasked months, skipping')\n",
    "        continue\n",
    "            \n",
    "    tgt_indices = window_df.loc[tgt_mask].sample(n=1).index\n",
    "\n",
    "    # Add an extra month index for each dropped month\n",
    "    tgt_indices.freq = 'ms'\n",
    "    for i in range(dropped_months-1):\n",
    "        tgt_indices = tgt_indices.append(pd.DatetimeIndex([tgt_indices[-1] + pd.DateOffset(months=1)]))\n",
    "\n",
    "    values = compute_filled_values(window_df, tgt_indices, point_id)\n",
    "\n",
    "    # Only keep values dictionaries that had data originally\n",
    "    values = [v for v in values if not np.isnan(v['original'])]\n",
    "\n",
    "    # Only keep 1 of the filled values from the window\n",
    "    output_list.extend(random.sample(values, 1))\n",
    "\n",
    "    del window_df, tgt_mask, tgt_indices, gap_mask\n",
    "    \n",
    "output_df = pd.DataFrame(output_list)\n",
    "comparison_stats(\n",
    "    output_df, x_col='original', y_cols=comparison_cols, \n",
    "    title='Randomly drop a two month gap during the year',\n",
    "    print_flag=True, write_flag=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91de9e31-8b9a-4298-a30f-7db36121e0fd",
   "metadata": {},
   "source": [
    "## Randomly drop a two month gap during the growing season (Apr-Sept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52d39b7a-a71f-4fd3-a64b-b213410044d9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly drop a two month gap during the growing season (Apr-Sept)\n",
      "            method     rmse      mae      mbe        m        b       r2        n\n",
      "       interpolate   0.1270   0.0964  -0.0243   0.8474   0.0824   0.8629   136544\n",
      "        climo_mean   0.1154   0.0842   0.0024   0.8813   0.0854   0.8822   136544\n",
      "      climo_median   0.1193   0.0812   0.0047   0.9020   0.0732   0.8751   136544\n",
      "             conor   0.0945   0.0708   0.0011   0.9204   0.0567   0.9210   136544\n",
      "     interp_clim_a   0.1040   0.0791  -0.0109   0.8644   0.0839   0.9074   136544\n",
      "     interp_clim_b   0.1042   0.0792  -0.0111   0.8642   0.0839   0.9071   136544\n",
      "     interp_clim_c   0.1042   0.0778  -0.0098   0.8747   0.0778   0.9058   136544\n",
      "       whit_a_0p50   0.1278   0.0960  -0.0120   0.8783   0.0731   0.8572   136544\n",
      "       whit_a_0p20   0.1267   0.0949  -0.0085   0.8961   0.0642   0.8601   136544\n",
      "       whit_a_0p10   0.1274   0.0953  -0.0070   0.9044   0.0598   0.8593   136544\n",
      "       whit_a_0p05   0.1286   0.0963  -0.0062   0.9096   0.0570   0.8573   136544\n",
      "       whit_a_0p01   0.1309   0.0981  -0.0054   0.9143   0.0544   0.8531   136544\n"
     ]
    }
   ],
   "source": [
    "dropped_months = 2\n",
    "months = [4, 5, 6, 7, 8, 9]\n",
    "\n",
    "output_list = []\n",
    "for point_id, year, window_df, year_month_mask in generate_windows(point_id_list, months=months):        \n",
    "\n",
    "    # For the target year, identify all the gap windows with at least 1 month of data\n",
    "    # This approach is assuming the gap will be 2 or months in the gap\n",
    "    gap_mask = window_df['etf'].notna()\n",
    "    for i in range(dropped_months-1):\n",
    "        gap_mask = gap_mask | window_df['etf'].notna().shift(-(i+1))\n",
    "        \n",
    "    tgt_mask = year_month_mask & gap_mask\n",
    "    if not tgt_mask.any():\n",
    "        print(f'{point_id} - {year} - no unmasked months, skipping')\n",
    "        continue\n",
    "            \n",
    "    tgt_indices = window_df.loc[tgt_mask].sample(n=1).index\n",
    "\n",
    "    # Add an extra month index for each dropped month\n",
    "    tgt_indices.freq = 'ms'\n",
    "    for i in range(dropped_months-1):\n",
    "        tgt_indices = tgt_indices.append(pd.DatetimeIndex([tgt_indices[-1] + pd.DateOffset(months=1)]))\n",
    "    \n",
    "    values = compute_filled_values(window_df, tgt_indices, point_id)\n",
    "\n",
    "    # Only keep values dictionaries that had data originally\n",
    "    values = [v for v in values if not np.isnan(v['original'])]\n",
    "\n",
    "    # Only keep 1 of the filled values from the window\n",
    "    output_list.extend(random.sample(values, 1))\n",
    "\n",
    "    del window_df, tgt_mask, tgt_indices, gap_mask\n",
    "    \n",
    "output_df = pd.DataFrame(output_list)\n",
    "comparison_stats(\n",
    "    output_df, x_col='original', y_cols=comparison_cols, \n",
    "    title='Randomly drop a two month gap during the growing season (Apr-Sept)',\n",
    "    print_flag=True, write_flag=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7793f5c4-5668-4021-84e3-be7d77eadd8d",
   "metadata": {},
   "source": [
    "## Randomly drop a two month gap during the non-growing season (Oct-Mar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6f65dd4-1aa0-43e3-9ff1-32ee65164b20",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly drop a two month gap during the non-growing season (Oct-Mar)\n",
      "            method     rmse      mae      mbe        m        b       r2        n\n",
      "       interpolate   0.1612   0.1213   0.0393   0.7960   0.1469   0.6743   135764\n",
      "        climo_mean   0.1338   0.1009   0.0001   0.7425   0.1360   0.7455   135764\n",
      "      climo_median   0.1383   0.0972  -0.0048   0.7602   0.1217   0.7297   135764\n",
      "             conor   0.1211   0.0914  -0.0013   0.7997   0.1044   0.7915   135764\n",
      "     interp_clim_a   0.1302   0.0991   0.0197   0.7692   0.1415   0.7644   135764\n",
      "     interp_clim_b   0.1332   0.1009   0.0215   0.7681   0.1438   0.7543   135764\n",
      "     interp_clim_c   0.1311   0.0981   0.0173   0.7781   0.1343   0.7603   135764\n",
      "       whit_a_0p50   0.1611   0.1209   0.0223   0.7950   0.1304   0.6639   135764\n",
      "       whit_a_0p20   0.1624   0.1215   0.0163   0.8042   0.1196   0.6602   135764\n",
      "       whit_a_0p10   0.1646   0.1231   0.0137   0.8097   0.1141   0.6541   135764\n",
      "       whit_a_0p05   0.1671   0.1250   0.0121   0.8134   0.1106   0.6475   135764\n",
      "       whit_a_0p01   0.1709   0.1279   0.0106   0.8173   0.1070   0.6373   135764\n"
     ]
    }
   ],
   "source": [
    "dropped_months = 2\n",
    "months = [10, 11, 12, 1, 2, 3]\n",
    "\n",
    "output_list = []\n",
    "for point_id, year, window_df, year_month_mask in generate_windows(point_id_list, months=months):        \n",
    "\n",
    "    # For the target year, identify all the gap windows with at least 1 month of data\n",
    "    # This approach is assuming the gap will be 2 or months in the gap\n",
    "    gap_mask = window_df['etf'].notna()\n",
    "    for i in range(dropped_months-1):\n",
    "        gap_mask = gap_mask | window_df['etf'].notna().shift(-(i+1))\n",
    "        \n",
    "    tgt_mask = year_month_mask & gap_mask\n",
    "    if not tgt_mask.any():\n",
    "        print(f'{point_id} - {year} - no unmasked months, skipping')\n",
    "        continue\n",
    "            \n",
    "    tgt_indices = window_df.loc[tgt_mask].sample(n=1).index\n",
    "\n",
    "    # Add an extra month index for each dropped month\n",
    "    tgt_indices.freq = 'ms'\n",
    "    for i in range(dropped_months-1):\n",
    "        tgt_indices = tgt_indices.append(pd.DatetimeIndex([tgt_indices[-1] + pd.DateOffset(months=1)]))\n",
    "    \n",
    "    values = compute_filled_values(window_df, tgt_indices, point_id)\n",
    "\n",
    "    # Only keep values dictionaries that had data originally\n",
    "    values = [v for v in values if not np.isnan(v['original'])]\n",
    "\n",
    "    # Only keep 1 of the filled values from the window\n",
    "    output_list.extend(random.sample(values, 1))\n",
    "\n",
    "    del window_df, tgt_mask, tgt_indices, gap_mask\n",
    "    \n",
    "output_df = pd.DataFrame(output_list)\n",
    "comparison_stats(\n",
    "    output_df, x_col='original', y_cols=comparison_cols, \n",
    "    title='Randomly drop a two month gap during the non-growing season (Oct-Mar)',\n",
    "    print_flag=True, write_flag=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb08c60-eb12-4360-9772-2f7ebde11715",
   "metadata": {},
   "source": [
    "## Randomly drop a three month gap during the year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e4816cf-6d05-4fbd-aa55-09b7c6e86ddd",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly drop a three month gap during the year\n",
      "            method     rmse      mae      mbe        m        b       r2        n\n",
      "       interpolate   0.1622   0.1231   0.0061   0.7749   0.1451   0.7392   136547\n",
      "        climo_mean   0.1244   0.0922   0.0019   0.8435   0.0985   0.8453   136547\n",
      "      climo_median   0.1285   0.0888   0.0008   0.8648   0.0843   0.8359   136547\n",
      "             conor   0.1119   0.0836   0.0010   0.8737   0.0789   0.8749   136547\n",
      "     interp_clim_a   0.1244   0.0948   0.0040   0.8092   0.1218   0.8471   136547\n",
      "     interp_clim_b   0.1264   0.0960   0.0049   0.8074   0.1238   0.8419   136547\n",
      "     interp_clim_c   0.1247   0.0936   0.0034   0.8199   0.1147   0.8454   136547\n",
      "       whit_a_0p50   0.1627   0.1220   0.0055   0.8201   0.1166   0.7435   136547\n",
      "       whit_a_0p20   0.1642   0.1228   0.0048   0.8385   0.1045   0.7429   136547\n",
      "       whit_a_0p10   0.1666   0.1245   0.0044   0.8470   0.0988   0.7386   136547\n",
      "       whit_a_0p05   0.1692   0.1265   0.0041   0.8523   0.0953   0.7333   136547\n",
      "       whit_a_0p01   0.1731   0.1296   0.0037   0.8571   0.0920   0.7248   136547\n"
     ]
    }
   ],
   "source": [
    "dropped_months = 3\n",
    "months = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "\n",
    "output_list = []\n",
    "for point_id, year, window_df, year_month_mask in generate_windows(point_id_list, months=months):        \n",
    "\n",
    "    # For the target year, identify all the gap windows with at least 1 month of data\n",
    "    # This approach is assuming the gap will be 2 or months in the gap\n",
    "    gap_mask = window_df['etf'].notna()\n",
    "    for i in range(dropped_months-1):\n",
    "        gap_mask = gap_mask | window_df['etf'].notna().shift(-(i+1))\n",
    "        \n",
    "    tgt_mask = year_month_mask & gap_mask\n",
    "    if not tgt_mask.any():\n",
    "        print(f'{point_id} - {year} - no unmasked months, skipping')\n",
    "        continue\n",
    "            \n",
    "    tgt_indices = window_df.loc[tgt_mask].sample(n=1).index\n",
    "\n",
    "    # Add an extra month index for each dropped month\n",
    "    tgt_indices.freq = 'ms'\n",
    "    for i in range(dropped_months-1):\n",
    "        tgt_indices = tgt_indices.append(pd.DatetimeIndex([tgt_indices[-1] + pd.DateOffset(months=1)]))\n",
    "    \n",
    "    values = compute_filled_values(window_df, tgt_indices, point_id)\n",
    "\n",
    "    # Only keep values dictionaries that had data originally\n",
    "    values = [v for v in values if not np.isnan(v['original'])]\n",
    "\n",
    "    # Only keep 1 of the filled values from the window\n",
    "    output_list.extend(random.sample(values, 1))\n",
    "\n",
    "    del window_df, tgt_mask, tgt_indices, gap_mask\n",
    "    \n",
    "output_df = pd.DataFrame(output_list)\n",
    "comparison_stats(\n",
    "    output_df, x_col='original', y_cols=comparison_cols, \n",
    "    title='Randomly drop a three month gap during the year',\n",
    "    print_flag=True, write_flag=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c296e378-65df-4982-b178-7a652a839353",
   "metadata": {},
   "source": [
    "## Randomly drop a three month gap during the growing season (Apr-Sept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "663b8979-838e-4636-b480-577d76db7a62",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly drop a three month gap during the growing season (Apr-Sept)\n",
      "            method     rmse      mae      mbe        m        b       r2        n\n",
      "       interpolate   0.1511   0.1148  -0.0330   0.7967   0.1072   0.8083   136544\n",
      "        climo_mean   0.1164   0.0850   0.0021   0.8800   0.0849   0.8804   136544\n",
      "      climo_median   0.1204   0.0820   0.0040   0.9009   0.0724   0.8731   136544\n",
      "             conor   0.1013   0.0754   0.0012   0.9067   0.0655   0.9095   136544\n",
      "     interp_clim_a   0.1140   0.0871  -0.0154   0.8383   0.0961   0.8904   136544\n",
      "     interp_clim_b   0.1145   0.0874  -0.0155   0.8378   0.0964   0.8894   136544\n",
      "     interp_clim_c   0.1140   0.0858  -0.0145   0.8488   0.0898   0.8890   136544\n",
      "       whit_a_0p50   0.1521   0.1135  -0.0154   0.8463   0.0907   0.8005   136544\n",
      "       whit_a_0p20   0.1526   0.1137  -0.0112   0.8658   0.0813   0.8008   136544\n",
      "       whit_a_0p10   0.1544   0.1150  -0.0096   0.8747   0.0768   0.7979   136544\n",
      "       whit_a_0p05   0.1564   0.1167  -0.0088   0.8800   0.0740   0.7940   136544\n",
      "       whit_a_0p01   0.1598   0.1194  -0.0080   0.8848   0.0714   0.7873   136544\n"
     ]
    }
   ],
   "source": [
    "dropped_months = 3\n",
    "months = [4, 5, 6, 7, 8, 9]\n",
    "\n",
    "output_list = []\n",
    "for point_id, year, window_df, year_month_mask in generate_windows(point_id_list, months=months):        \n",
    "\n",
    "    # For the target year, identify all the gap windows with at least 1 month of data\n",
    "    # This approach is assuming the gap will be 2 or months in the gap\n",
    "    gap_mask = window_df['etf'].notna()\n",
    "    for i in range(dropped_months-1):\n",
    "        gap_mask = gap_mask | window_df['etf'].notna().shift(-(i+1))\n",
    "        \n",
    "    tgt_mask = year_month_mask & gap_mask\n",
    "    if not tgt_mask.any():\n",
    "        print(f'{point_id} - {year} - no unmasked months, skipping')\n",
    "        continue\n",
    "            \n",
    "    tgt_indices = window_df.loc[tgt_mask].sample(n=1).index\n",
    "\n",
    "    # Add an extra month index for each dropped month\n",
    "    tgt_indices.freq = 'ms'\n",
    "    for i in range(dropped_months-1):\n",
    "        tgt_indices = tgt_indices.append(pd.DatetimeIndex([tgt_indices[-1] + pd.DateOffset(months=1)]))\n",
    "    \n",
    "    values = compute_filled_values(window_df, tgt_indices, point_id)\n",
    "\n",
    "    # Only keep values dictionaries that had data originally\n",
    "    values = [v for v in values if not np.isnan(v['original'])]\n",
    "\n",
    "    # Only keep 1 of the filled values from the window\n",
    "    output_list.extend(random.sample(values, 1))\n",
    "\n",
    "    del window_df, tgt_mask, tgt_indices, gap_mask\n",
    "    \n",
    "output_df = pd.DataFrame(output_list)\n",
    "comparison_stats(\n",
    "    output_df, x_col='original', y_cols=comparison_cols, \n",
    "    title='Randomly drop a three month gap during the growing season (Apr-Sept)',\n",
    "    print_flag=True, write_flag=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b120b884-cca6-4580-b4d2-122241835bd3",
   "metadata": {},
   "source": [
    "## Randomly drop a three month gap during the non-growing season (Oct-Mar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "11a8ea1a-9b0a-44dd-b2e3-5f8c55f37f64",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly drop a three month gap during the non-growing season (Oct-Mar)\n",
      "            method     rmse      mae      mbe        m        b       r2        n\n",
      "       interpolate   0.1750   0.1326   0.0483   0.7839   0.1652   0.6487   135764\n",
      "        climo_mean   0.1331   0.1003   0.0002   0.7588   0.1307   0.7622   135764\n",
      "      climo_median   0.1376   0.0964  -0.0041   0.7784   0.1158   0.7475   135764\n",
      "             conor   0.1224   0.0924  -0.0007   0.7989   0.1081   0.7991   135764\n",
      "     interp_clim_a   0.1353   0.1033   0.0242   0.7714   0.1480   0.7625   135764\n",
      "     interp_clim_b   0.1389   0.1055   0.0263   0.7689   0.1513   0.7507   135764\n",
      "     interp_clim_c   0.1359   0.1022   0.0221   0.7812   0.1405   0.7593   135764\n",
      "       whit_a_0p50   0.1742   0.1313   0.0279   0.7898   0.1417   0.6390   135764\n",
      "       whit_a_0p20   0.1764   0.1327   0.0217   0.7983   0.1308   0.6322   135764\n",
      "       whit_a_0p10   0.1795   0.1350   0.0191   0.8032   0.1256   0.6240   135764\n",
      "       whit_a_0p05   0.1826   0.1373   0.0175   0.8064   0.1222   0.6157   135764\n",
      "       whit_a_0p01   0.1871   0.1409   0.0159   0.8094   0.1191   0.6036   135764\n"
     ]
    }
   ],
   "source": [
    "dropped_months = 3\n",
    "months = [10, 11, 12, 1, 2, 3]\n",
    "\n",
    "output_list = []\n",
    "for point_id, year, window_df, year_month_mask in generate_windows(point_id_list, months=months):        \n",
    "\n",
    "    # For the target year, identify all the gap windows with at least 1 month of data\n",
    "    # This approach is assuming the gap will be 2 or months in the gap\n",
    "    gap_mask = window_df['etf'].notna()\n",
    "    for i in range(dropped_months-1):\n",
    "        gap_mask = gap_mask | window_df['etf'].notna().shift(-(i+1))\n",
    "        \n",
    "    tgt_mask = year_month_mask & gap_mask\n",
    "    if not tgt_mask.any():\n",
    "        print(f'{point_id} - {year} - no unmasked months, skipping')\n",
    "        continue\n",
    "            \n",
    "    tgt_indices = window_df.loc[tgt_mask].sample(n=1).index\n",
    "\n",
    "    # Add an extra month index for each dropped month\n",
    "    tgt_indices.freq = 'ms'\n",
    "    for i in range(dropped_months-1):\n",
    "        tgt_indices = tgt_indices.append(pd.DatetimeIndex([tgt_indices[-1] + pd.DateOffset(months=1)]))\n",
    "    \n",
    "    values = compute_filled_values(window_df, tgt_indices, point_id)\n",
    "\n",
    "    # Only keep values dictionaries that had data originally\n",
    "    values = [v for v in values if not np.isnan(v['original'])]\n",
    "\n",
    "    # Only keep 1 of the filled values from the window\n",
    "    output_list.extend(random.sample(values, 1))\n",
    "\n",
    "    del window_df, tgt_mask, tgt_indices, gap_mask\n",
    "    \n",
    "output_df = pd.DataFrame(output_list)\n",
    "comparison_stats(\n",
    "    output_df, x_col='original', y_cols=comparison_cols, \n",
    "    title='Randomly drop a three month gap during the non-growing season (Oct-Mar)',\n",
    "    print_flag=True, write_flag=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7574ea-ec3f-4318-9356-c9b88c3a14e7",
   "metadata": {},
   "source": [
    "## Randomly drop a four month gap during the year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c66d4aa-af4d-41e4-9444-99fbe6be29af",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly drop a four month gap during the year\n",
      "            method     rmse      mae      mbe        m        b       r2        n\n",
      "       interpolate   0.1812   0.1380   0.0054   0.7371   0.1681   0.6773   136547\n",
      "        climo_mean   0.1242   0.0920   0.0012   0.8447   0.0973   0.8458   136547\n",
      "      climo_median   0.1282   0.0886   0.0001   0.8659   0.0831   0.8366   136547\n",
      "             conor   0.1143   0.0852   0.0005   0.8676   0.0825   0.8694   136547\n",
      "     interp_clim_a   0.1316   0.1008   0.0033   0.7909   0.1327   0.8286   136547\n",
      "     interp_clim_b   0.1341   0.1022   0.0044   0.7885   0.1353   0.8219   136547\n",
      "     interp_clim_c   0.1317   0.0995   0.0027   0.8015   0.1256   0.8275   136547\n",
      "       whit_a_0p50   0.1823   0.1365   0.0055   0.7927   0.1338   0.6850   136547\n",
      "       whit_a_0p20   0.1849   0.1381   0.0048   0.8118   0.1212   0.6828   136547\n",
      "       whit_a_0p10   0.1881   0.1405   0.0043   0.8204   0.1154   0.6769   136547\n",
      "       whit_a_0p05   0.1913   0.1430   0.0039   0.8253   0.1120   0.6701   136547\n",
      "       whit_a_0p01   0.1960   0.1468   0.0033   0.8294   0.1089   0.6596   136547\n"
     ]
    }
   ],
   "source": [
    "dropped_months = 4\n",
    "months = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "\n",
    "output_list = []\n",
    "for point_id, year, window_df, year_month_mask in generate_windows(point_id_list, months=months):        \n",
    "\n",
    "    # For the target year, identify all the gap windows with at least 1 month of data\n",
    "    # This approach is assuming the gap will be 2 or months in the gap\n",
    "    gap_mask = window_df['etf'].notna()\n",
    "    for i in range(dropped_months-1):\n",
    "        gap_mask = gap_mask | window_df['etf'].notna().shift(-(i+1))\n",
    "        \n",
    "    tgt_mask = year_month_mask & gap_mask\n",
    "    if not tgt_mask.any():\n",
    "        print(f'{point_id} - {year} - no unmasked months, skipping')\n",
    "        continue\n",
    "            \n",
    "    tgt_indices = window_df.loc[tgt_mask].sample(n=1).index\n",
    "\n",
    "    # Add an extra month index for each dropped month\n",
    "    tgt_indices.freq = 'ms'\n",
    "    for i in range(dropped_months-1):\n",
    "        tgt_indices = tgt_indices.append(pd.DatetimeIndex([tgt_indices[-1] + pd.DateOffset(months=1)]))\n",
    "    \n",
    "    values = compute_filled_values(window_df, tgt_indices, point_id)\n",
    "\n",
    "    # Only keep values dictionaries that had data originally\n",
    "    values = [v for v in values if not np.isnan(v['original'])]\n",
    "\n",
    "    # Only keep 1 of the filled values from the window\n",
    "    output_list.extend(random.sample(values, 1))\n",
    "\n",
    "    del window_df, tgt_mask, tgt_indices, gap_mask\n",
    "    \n",
    "output_df = pd.DataFrame(output_list)\n",
    "comparison_stats(\n",
    "    output_df, x_col='original', y_cols=comparison_cols, \n",
    "    title='Randomly drop a four month gap during the year',\n",
    "    print_flag=True, write_flag=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08fb42f-a6ce-4163-8309-3e8c6d5fec6a",
   "metadata": {},
   "source": [
    "## Randomly drop a four month gap during the growing season (Apr-Sept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "977f6372-7cd7-408b-98f4-f3dc79a0919b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly drop a four month gap during the growing season (Apr-Sept)\n",
      "            method     rmse      mae      mbe        m        b       r2        n\n",
      "       interpolate   0.1760   0.1340  -0.0363   0.7395   0.1394   0.7374   136544\n",
      "        climo_mean   0.1162   0.0854   0.0021   0.8782   0.0843   0.8805   136544\n",
      "      climo_median   0.1198   0.0822   0.0034   0.8994   0.0713   0.8738   136544\n",
      "             conor   0.1056   0.0784   0.0014   0.8977   0.0704   0.9014   136544\n",
      "     interp_clim_a   0.1240   0.0953  -0.0171   0.8088   0.1119   0.8708   136544\n",
      "     interp_clim_b   0.1251   0.0959  -0.0169   0.8077   0.1129   0.8682   136544\n",
      "     interp_clim_c   0.1235   0.0938  -0.0164   0.8194   0.1054   0.8703   136544\n",
      "       whit_a_0p50   0.1780   0.1322  -0.0169   0.8038   0.1155   0.7297   136544\n",
      "       whit_a_0p20   0.1805   0.1336  -0.0120   0.8252   0.1059   0.7264   136544\n",
      "       whit_a_0p10   0.1836   0.1359  -0.0102   0.8343   0.1016   0.7206   136544\n",
      "       whit_a_0p05   0.1866   0.1383  -0.0093   0.8394   0.0991   0.7143   136544\n",
      "       whit_a_0p01   0.1912   0.1420  -0.0086   0.8435   0.0970   0.7045   136544\n"
     ]
    }
   ],
   "source": [
    "dropped_months = 4\n",
    "months = [4, 5, 6, 7, 8, 9]\n",
    "\n",
    "output_list = []\n",
    "for point_id, year, window_df, year_month_mask in generate_windows(point_id_list, months=months):        \n",
    "\n",
    "    # For the target year, identify all the gap windows with at least 1 month of data\n",
    "    # This approach is assuming the gap will be 2 or months in the gap\n",
    "    gap_mask = window_df['etf'].notna()\n",
    "    for i in range(dropped_months-1):\n",
    "        gap_mask = gap_mask | window_df['etf'].notna().shift(-(i+1))\n",
    "        \n",
    "    tgt_mask = year_month_mask & gap_mask\n",
    "    if not tgt_mask.any():\n",
    "        print(f'{point_id} - {year} - no unmasked months, skipping')\n",
    "        continue\n",
    "            \n",
    "    tgt_indices = window_df.loc[tgt_mask].sample(n=1).index\n",
    "\n",
    "    # Add an extra month index for each dropped month\n",
    "    tgt_indices.freq = 'ms'\n",
    "    for i in range(dropped_months-1):\n",
    "        tgt_indices = tgt_indices.append(pd.DatetimeIndex([tgt_indices[-1] + pd.DateOffset(months=1)]))\n",
    "    \n",
    "    values = compute_filled_values(window_df, tgt_indices, point_id)\n",
    "\n",
    "    # Only keep values dictionaries that had data originally\n",
    "    values = [v for v in values if not np.isnan(v['original'])]\n",
    "\n",
    "    # Only keep 1 of the filled values from the window\n",
    "    output_list.extend(random.sample(values, 1))\n",
    "\n",
    "    del window_df, tgt_mask, tgt_indices, gap_mask\n",
    "    \n",
    "output_df = pd.DataFrame(output_list)\n",
    "comparison_stats(\n",
    "    output_df, x_col='original', y_cols=comparison_cols, \n",
    "    title='Randomly drop a four month gap during the growing season (Apr-Sept)',\n",
    "    print_flag=True, write_flag=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b09d1b-c54c-4087-a1d6-34f09a2f7cbe",
   "metadata": {},
   "source": [
    "## Randomly drop a four month gap during the non-growing season (Oct-Mar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09627736-2f31-4a93-ab47-bc0b325fae95",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly drop a four month gap during the non-growing season (Oct-Mar)\n",
      "            method     rmse      mae      mbe        m        b       r2        n\n",
      "       interpolate   0.1857   0.1413   0.0489   0.7744   0.1751   0.6323   135764\n",
      "        climo_mean   0.1312   0.0987   0.0006   0.7824   0.1223   0.7857   135764\n",
      "      climo_median   0.1353   0.0948  -0.0030   0.8030   0.1072   0.7730   135764\n",
      "             conor   0.1220   0.0920  -0.0002   0.8124   0.1048   0.8145   135764\n",
      "     interp_clim_a   0.1383   0.1059   0.0247   0.7784   0.1487   0.7695   135764\n",
      "     interp_clim_b   0.1422   0.1082   0.0268   0.7752   0.1526   0.7575   135764\n",
      "     interp_clim_c   0.1387   0.1048   0.0229   0.7887   0.1412   0.7675   135764\n",
      "       whit_a_0p50   0.1851   0.1398   0.0285   0.7926   0.1446   0.6271   135764\n",
      "       whit_a_0p20   0.1878   0.1415   0.0220   0.8020   0.1328   0.6200   135764\n",
      "       whit_a_0p10   0.1911   0.1440   0.0191   0.8070   0.1271   0.6118   135764\n",
      "       whit_a_0p05   0.1945   0.1466   0.0173   0.8103   0.1235   0.6034   135764\n",
      "       whit_a_0p01   0.1995   0.1506   0.0157   0.8134   0.1201   0.5910   135764\n"
     ]
    }
   ],
   "source": [
    "dropped_months = 4\n",
    "months = [10, 11, 12, 1, 2, 3]\n",
    "\n",
    "output_list = []\n",
    "for point_id, year, window_df, year_month_mask in generate_windows(point_id_list, months=months):        \n",
    "\n",
    "    # For the target year, identify all the gap windows with at least 1 month of data\n",
    "    # This approach is assuming the gap will be 2 or months in the gap\n",
    "    gap_mask = window_df['etf'].notna()\n",
    "    for i in range(dropped_months-1):\n",
    "        gap_mask = gap_mask | window_df['etf'].notna().shift(-(i+1))\n",
    "        \n",
    "    tgt_mask = year_month_mask & gap_mask\n",
    "    if not tgt_mask.any():\n",
    "        print(f'{point_id} - {year} - no unmasked months, skipping')\n",
    "        continue\n",
    "            \n",
    "    tgt_indices = window_df.loc[tgt_mask].sample(n=1).index\n",
    "\n",
    "    # Add an extra month index for each dropped month\n",
    "    tgt_indices.freq = 'ms'\n",
    "    for i in range(dropped_months-1):\n",
    "        tgt_indices = tgt_indices.append(pd.DatetimeIndex([tgt_indices[-1] + pd.DateOffset(months=1)]))\n",
    "    \n",
    "    values = compute_filled_values(window_df, tgt_indices, point_id)\n",
    "\n",
    "    # Only keep values dictionaries that had data originally\n",
    "    values = [v for v in values if not np.isnan(v['original'])]\n",
    "\n",
    "    # Only keep 1 of the filled values from the window\n",
    "    output_list.extend(random.sample(values, 1))\n",
    "\n",
    "    del window_df, tgt_mask, tgt_indices, gap_mask\n",
    "    \n",
    "output_df = pd.DataFrame(output_list)\n",
    "comparison_stats(\n",
    "    output_df, x_col='original', y_cols=comparison_cols, \n",
    "    title='Randomly drop a four month gap during the non-growing season (Oct-Mar)',\n",
    "    print_flag=True, write_flag=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b6ffa0-d32b-4bb0-acd0-e67878325214",
   "metadata": {},
   "source": [
    "## Randomly drop a six month gap during the year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "edf4c360-f27c-403c-a247-c389060dfed0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32mpandas/_libs/index.pyx:627\u001b[0m, in \u001b[0;36mpandas._libs.index.DatetimeEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2606\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2630\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: -9223372036854775808",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/openet-v21/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3811\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:595\u001b[0m, in \u001b[0;36mpandas._libs.index.DatetimeEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:629\u001b[0m, in \u001b[0;36mpandas._libs.index.DatetimeEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: NaT",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/openet-v21/lib/python3.11/site-packages/pandas/core/indexes/datetimes.py:630\u001b[0m, in \u001b[0;36mDatetimeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 630\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mIndex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniconda3/envs/openet-v21/lib/python3.11/site-packages/pandas/core/indexes/base.py:3819\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3818\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3819\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3820\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3821\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3822\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3823\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: NaT",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(dropped_months\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     23\u001b[0m     tgt_indices \u001b[38;5;241m=\u001b[39m tgt_indices\u001b[38;5;241m.\u001b[39mappend(pd\u001b[38;5;241m.\u001b[39mDatetimeIndex([tgt_indices[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m pd\u001b[38;5;241m.\u001b[39mDateOffset(months\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]))\n\u001b[0;32m---> 25\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_filled_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwindow_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoint_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Only keep values dictionaries that had data originally\u001b[39;00m\n\u001b[1;32m     28\u001b[0m values \u001b[38;5;241m=\u001b[39m [v \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misnan(v[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moriginal\u001b[39m\u001b[38;5;124m'\u001b[39m])]\n",
      "Cell \u001b[0;32mIn[7], line 128\u001b[0m, in \u001b[0;36mcompute_filled_values\u001b[0;34m(window_df, tgt_indices, point_id)\u001b[0m\n\u001b[1;32m    126\u001b[0m next_index \u001b[38;5;241m=\u001b[39m window_next_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124metf\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfirst_valid_index()\n\u001b[1;32m    127\u001b[0m prev_i \u001b[38;5;241m=\u001b[39m window_df\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_loc(prev_index)\n\u001b[0;32m--> 128\u001b[0m next_i \u001b[38;5;241m=\u001b[39m \u001b[43mwindow_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m w_prev \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m (tgt_i \u001b[38;5;241m-\u001b[39m prev_i))\n\u001b[1;32m    130\u001b[0m w_next \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m (next_i \u001b[38;5;241m-\u001b[39m tgt_i))\n",
      "File \u001b[0;32m~/miniconda3/envs/openet-v21/lib/python3.11/site-packages/pandas/core/indexes/datetimes.py:632\u001b[0m, in \u001b[0;36mDatetimeIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Index\u001b[38;5;241m.\u001b[39mget_loc(\u001b[38;5;28mself\u001b[39m, key)\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 632\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(orig_key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: None"
     ]
    }
   ],
   "source": [
    "dropped_months = 6\n",
    "months = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "\n",
    "output_list = []\n",
    "for point_id, year, window_df, year_month_mask in generate_windows(point_id_list, months=months):        \n",
    "\n",
    "    # For the target year, identify all the gap windows with at least 1 month of data\n",
    "    # This approach is assuming the gap will be 2 or months in the gap\n",
    "    gap_mask = window_df['etf'].notna()\n",
    "    for i in range(dropped_months-1):\n",
    "        gap_mask = gap_mask | window_df['etf'].notna().shift(-(i+1))\n",
    "        \n",
    "    tgt_mask = year_month_mask & gap_mask\n",
    "    if not tgt_mask.any():\n",
    "        print(f'{point_id} - {year} - no unmasked months, skipping')\n",
    "        continue\n",
    "            \n",
    "    tgt_indices = window_df.loc[tgt_mask].sample(n=1).index\n",
    "\n",
    "    # Add an extra month index for each dropped month\n",
    "    tgt_indices.freq = 'ms'\n",
    "    for i in range(dropped_months-1):\n",
    "        tgt_indices = tgt_indices.append(pd.DatetimeIndex([tgt_indices[-1] + pd.DateOffset(months=1)]))\n",
    "    \n",
    "    values = compute_filled_values(window_df, tgt_indices, point_id)\n",
    "\n",
    "    # Only keep values dictionaries that had data originally\n",
    "    values = [v for v in values if not np.isnan(v['original'])]\n",
    "\n",
    "    # Only keep 1 of the filled values from the window\n",
    "    output_list.extend(random.sample(values, 1))\n",
    "\n",
    "    del window_df, tgt_mask, tgt_indices, gap_mask\n",
    "    \n",
    "output_df = pd.DataFrame(output_list)\n",
    "comparison_stats(\n",
    "    output_df, x_col='original', y_cols=comparison_cols, \n",
    "    title='Randomly drop a six month gap during the year',\n",
    "    print_flag=True, write_flag=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78de2054-fa26-4bac-8283-fc5b6adc48fe",
   "metadata": {},
   "source": [
    "## Randomly drop a six month gap during the growing season (Apr-Sept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f264e5-1109-453a-837c-f1c756c7096a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dropped_months = 6\n",
    "months = [4, 5, 6, 7, 8, 9]\n",
    "\n",
    "output_list = []\n",
    "for point_id, year, window_df, year_month_mask in generate_windows(point_id_list, months=months):        \n",
    "\n",
    "    # For the target year, identify all the gap windows with at least 1 month of data\n",
    "    # This approach is assuming the gap will be 2 or months in the gap\n",
    "    gap_mask = window_df['etf'].notna()\n",
    "    for i in range(dropped_months-1):\n",
    "        gap_mask = gap_mask | window_df['etf'].notna().shift(-(i+1))\n",
    "        \n",
    "    tgt_mask = year_month_mask & gap_mask\n",
    "    if not tgt_mask.any():\n",
    "        print(f'{point_id} - {year} - no unmasked months, skipping')\n",
    "        continue\n",
    "            \n",
    "    tgt_indices = window_df.loc[tgt_mask].sample(n=1).index\n",
    "\n",
    "    # Add an extra month index for each dropped month\n",
    "    tgt_indices.freq = 'ms'\n",
    "    for i in range(dropped_months-1):\n",
    "        tgt_indices = tgt_indices.append(pd.DatetimeIndex([tgt_indices[-1] + pd.DateOffset(months=1)]))\n",
    "    \n",
    "    values = compute_filled_values(window_df, tgt_indices, point_id)\n",
    "\n",
    "    # Only keep values dictionaries that had data originally\n",
    "    values = [v for v in values if not np.isnan(v['original'])]\n",
    "\n",
    "    # Only keep 1 of the filled values from the window\n",
    "    output_list.extend(random.sample(values, 1))\n",
    "\n",
    "    del window_df, tgt_mask, tgt_indices, gap_mask\n",
    "    \n",
    "output_df = pd.DataFrame(output_list)\n",
    "comparison_stats(\n",
    "    output_df, x_col='original', y_cols=comparison_cols, \n",
    "    title='Randomly drop a six month gap during the growing season (Apr-Sept)',\n",
    "    print_flag=True, write_flag=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f602c8e-db0e-43de-bcaa-cb798d87b522",
   "metadata": {},
   "source": [
    "## Randomly drop a six month gap during the non-growing season (Oct-Mar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38631852-2a16-41c6-83d7-11eb429175b2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "dropped_months = 6\n",
    "months = [10, 11, 12, 1, 2, 3]\n",
    "\n",
    "output_list = []\n",
    "for point_id, year, window_df, year_month_mask in generate_windows(point_id_list, months=months):        \n",
    "\n",
    "    # For the target year, identify all the gap windows with at least 1 month of data\n",
    "    # This approach is assuming the gap will be 2 or months in the gap\n",
    "    gap_mask = window_df['etf'].notna()\n",
    "    for i in range(dropped_months-1):\n",
    "        gap_mask = gap_mask | window_df['etf'].notna().shift(-(i+1))\n",
    "        \n",
    "    tgt_mask = year_month_mask & gap_mask\n",
    "    if not tgt_mask.any():\n",
    "        print(f'{point_id} - {year} - no unmasked months, skipping')\n",
    "        continue\n",
    "\n",
    "    tgt_indices = window_df.loc[tgt_mask].sample(n=1).index\n",
    "\n",
    "    # Add an extra month index for each dropped month\n",
    "    tgt_indices.freq = 'ms'\n",
    "    for i in range(dropped_months-1):\n",
    "        tgt_indices = tgt_indices.append(pd.DatetimeIndex([tgt_indices[-1] + pd.DateOffset(months=1)]))\n",
    "    \n",
    "    values = compute_filled_values(window_df, tgt_indices, point_id)\n",
    "\n",
    "    # Only keep values dictionaries that had data originally\n",
    "    values = [v for v in values if not np.isnan(v['original'])]\n",
    "\n",
    "    # Only keep 1 of the filled values from the window\n",
    "    output_list.extend(random.sample(values, 1))\n",
    "\n",
    "    del window_df, tgt_mask, tgt_indices, gap_mask\n",
    "    \n",
    "output_df = pd.DataFrame(output_list)\n",
    "comparison_stats(\n",
    "    output_df, x_col='original', y_cols=comparison_cols, \n",
    "    title='Randomly drop a six month gap during the non-growing season (Oct-Mar)',\n",
    "    print_flag=True, write_flag=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44cb88e-5b9b-47ce-bbcb-9c6df1a8b595",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100a7529-8cf5-4c5d-a695-13ba734543b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43851d1b-2366-42d9-bd1d-2ceae0f94780",
   "metadata": {},
   "source": [
    "### Old plotting function code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c208c8a4-78d1-4c40-be24-b159dca3c90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.pairplot(\n",
    "#     output_df[['original'] + comparison_cols], corner=True, kind='reg',\n",
    "#     plot_kws={'scatter_kws': {'s': 2, 'alpha': 0.2}, 'line_kws': {'color': 'red'}},\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9638fb56-7e97-4e9d-94a8-10706b3bea43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.pairplot(output_df[['original'] + comparison_cols], corner=True, kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8a6c83-0de5-4a82-be07-3db9a207c9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.pairplot(output_df[['original'] + comparison_cols], corner=True, kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc92226-0f5b-4b4b-864b-8a8753d7ab7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = sns.pairplot(\n",
    "#     output_df, x_vars = ['original'], y_vars = comparison_cols, kind='reg', \n",
    "#     plot_kws={'scatter_kws': {'s': 1, 'alpha': 0.1}, 'line_kws': {'color': 'red'}},\n",
    "# )\n",
    "# for ax in g.axes.flatten():\n",
    "#     if ax:\n",
    "#         ax.set_xlim(0, 1.2)\n",
    "#         ax.set_ylim(0, 1.2)\n",
    "#         ax.set_aspect('equal')\n",
    "#         ax.set_xticks([0, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2])\n",
    "#         ax.axline((0, 0), slope=1, color='gray', linestyle='--')  # linewidth=1\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563b5a75-aa0b-434d-af45-f8ad573741b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.pairplot(\n",
    "#     output_df[['original'] + comparison_cols], corner=True, kind='reg',\n",
    "#     plot_kws={'scatter_kws': {'s': 2, 'alpha': 0.1}, 'line_kws': {'color': 'red'}},\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
